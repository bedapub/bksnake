Topic Title - bksnake - Bulk RNASeq Snakemake Workflow
######################################################

Report generated by Snakemake


`bksnake` - bulk RNASeq Snakemake workflow
==========================================


Description
***********


`bksnake` is a *Snakemake* (`Moelder et al. 2021 <https://f1000research.com/articles/10-33/v1>`_) workflow for bulk RNASeq data analysis. It uses *STAR* aligner (`Dobin et al. 2012 <https://academic.oup.com/bioinformatics/article/29/1/15/272537>`_) for read mapping and *FeatureCounts* from the *Subread package* (`Liao et al. 2014 <https://pubmed.ncbi.nlm.nih.gov/24227677/>`_) for gene quantification. 

Reference genomes with *RefSeq* and *Ensembl* gene annotations are available for several species such as *hg38, chm13, mm10, mm39, rn6, rn7, mfa5, mfa6, ss11*, and *oc2*. The generation of these reference genomes and annotation files is documented in a separate repository on github (see `refsnake <https://github.com/bedapub/refsnake/tree/main>`_). 

Data quality and RNASeq metrics are determined using *FastQC* (`Andrews et al. <https://www.bioinformatics.babraham.ac.uk/projects/fastqc/>`_), *MultiQC* (`Ewels et al. 2016 <https://academic.oup.com/bioinformatics/article/32/19/3047/2196507>`_), and *Picard* tools (`Broad Institute <http://broadinstitute.github.io/picard/>`_). In addition, diagnostic plots for data quality assessment such as *BioQC* tissue heterogeneity (`Zhang et al. 2017 <https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-017-3661-2>`_) or *Principal Component Analysis* are provided within this HTML report. 

Optionally, genome coverage files (*BigWig*) and read alignment files (*BAM/CRAM*) can be generated as well. Input read trimming with *Cutadapt* (`Martin 2011 <https://cutadapt.readthedocs.io/en/stable>`_) and generation of *unmapped reads* are also available. 

The pipeline can be launched via a helper tool, ``run.py``, or directly with Snakemake for users familiar with the workflow tool. All parameters for the pipeline are specified within a configuration *yaml* file or explicitly on the command line when using ``run.py``. 

All input data, i.e. input fastq files, a human-readable tab-delimited file describing the samples, as well as the reference genome and STAR index files, must be available to the pipeline in a local data folder. To run the pipeline, Snakemake and `Singularity <https://sylabs.io/docs/>`_ must be installed and pre-configured. 

All software tools used by the pipeline are pulled from public *Singularity* or *Docker* image repositories. It is recommended to run the pipeline on a high-performance cluster environment.


Results
*******

{{ snakemake.config["TOTAL_NUMBER_OF_SAMPLES"] }} samples in {{ snakemake.config["TOTAL_NUMBER_OF_GROUPS"] }} different groups (conditions) were processed.
{{ snakemake.config["species"] }} was used as reference genome.


Workflow
********

.. image:: rulegraph.png
  :width: 400
  :alt: Alternative text
